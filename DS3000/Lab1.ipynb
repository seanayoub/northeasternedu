{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52a63c5-8632-42cf-a598-1f9b9fcf118e",
   "metadata": {},
   "source": [
    "# Lab 1 (Due @ by 11:59 pm via Canvas/Gradescope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca321b-3edd-4428-8109-d473e4b6d195",
   "metadata": {},
   "source": [
    "\n",
    "Due: Tuesday Sep 26 @ 11:59 PM EST\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the `ipynb` file to gradescope.\n",
    "\n",
    "### Group Work\n",
    "\n",
    "You are encouraged to work in groups for this Lab, however each student should submit their own notebook file to Gradescope. While each Part of the Lab depends on previous parts, talking through the problem with your group should help speed up both understanding and arriving at a solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "128c2500-de83-4732-a3ac-78ccdd6094f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will use the below modules on this lab\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197c58c-8285-446e-bb07-347de63ce276",
   "metadata": {},
   "source": [
    "## Part 1: Web Scraping Warm-Up (20 points)\n",
    "\n",
    "Build a `df_premier` which contains the names and stadiums of all the current English Premier League Teams based [on this website](https://www.premierleague.com/clubs):\n",
    "\n",
    "    df_premier.head()\n",
    "    \n",
    "yields an output:\n",
    "\n",
    "| name                   | stadium                 |\n",
    "|------------------------|-------------------------|\n",
    "| Arsenal                | Emirates Stadium        |\n",
    "| Aston Villa            | Villa Park              |\n",
    "| AFC Bournemouth        | Vitality Stadium        |\n",
    "| Brentford              | Gtech Community Stadium |\n",
    "| Brighton & Hove Albion | Amex Stadium            |\n",
    "\n",
    "Make sure you: \n",
    "- use BeautifulSoup\n",
    "- print the `.head()` of the data frame when you are finished\n",
    "\n",
    "**Hint:** there should only be two `class_` values you need to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e714b998-d20c-4119-a463-38c180001261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stadium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Emirates Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Villa Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Vitality Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brentford</td>\n",
       "      <td>Gtech Community Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brighton &amp; Hove Albion</td>\n",
       "      <td>Amex Stadium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                  stadium\n",
       "0                 Arsenal         Emirates Stadium\n",
       "1             Aston Villa               Villa Park\n",
       "2             Bournemouth         Vitality Stadium\n",
       "3               Brentford  Gtech Community Stadium\n",
       "4  Brighton & Hove Albion             Amex Stadium"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_html = requests.get(\"https://www.premierleague.com/clubs\").text\n",
    "soup = BeautifulSoup(str_html)\n",
    "\n",
    "team_list = []\n",
    "for team in soup.find_all(class_ = \"club-card__name\"):\n",
    "    team_name = team.text\n",
    "    team_list.append(team_name)\n",
    "\n",
    "stadium_list = []\n",
    "for stadium in soup.find_all(class_ = \"club-card__stadium\"):\n",
    "    stadium_name = stadium.text\n",
    "    stadium_list.append(stadium_name)\n",
    "\n",
    "premier_dict = {\"name\": team_list,\n",
    "               \"stadium\": stadium_list}\n",
    "df_premier = pd.DataFrame.from_dict(premier_dict)\n",
    "\n",
    "df_premier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c384e097-798c-4462-a6d0-329e37b4ceb0",
   "metadata": {},
   "source": [
    "# Part 2: A Trickier Web Scraper\n",
    "\n",
    "For this problem, we will (together) create a small data set scraped from [flightaware.com](https://flightaware.com/) which includes some details from the current flight schedule at Boston Logan Airport. You will build the first two parts of the data pipeline as functions (Parts 2.1 and 2.2) and then provide a detailed overview/description of the last two parts of the pipeline based on code I have written/provided (Parts 2.3 and 2.4). Please do not take these final two parts lightly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b6eb5-bf20-4a91-9967-f78fe2f8c80f",
   "metadata": {},
   "source": [
    "## Part 2.1: The Scraper Function (20 points)\n",
    "\n",
    "Complete the function `get_airport_html()` below (including docstring) which visits the url of a given US airport code and grabs the html. Visit [flightaware.com](https://flightaware.com/) and type in a few codes (e.g. BOS, JFK, LAX, RDU) and notice the pattern in the url so that you can pass any airport code to the function as a string. **Make sure to remove the `pass` statement when you are finished**. I have written the code you should run once the function is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f8cca2-7c10-4e29-8c8c-061044eb0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_html(code):\n",
    "    \"\"\" completes a web call based on a given US airport code\n",
    "    \n",
    "    Args:\n",
    "        code (str): desired US airport code\n",
    "        \n",
    "    Returns:\n",
    "        html (str): html response from flightaware.com\n",
    "    \"\"\"\n",
    "    url = f\"https://www.flightaware.com/live/airport/K{code}\"\n",
    "    html = requests.get(url).text\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142e684f-b455-49f4-8784-4959cffa76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you are done the following code should be run\n",
    "url_text = get_airport_html('BOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfca310-6271-45d6-9d1d-ee5caf2d0115",
   "metadata": {},
   "source": [
    "## Part 2.2: The Soup Function (20 points)\n",
    "\n",
    "Complete the function `get_airport_table_soup()` below (including docstring) which takes the html from the previous function and outputs one of four beautiful soup objects, depending on the board you are interested in as defined by the `'id'` attribute:\n",
    "\n",
    "    - `id='arrivals-board'`\n",
    "    - `id='departures-board'`\n",
    "    - `id='enroute-board'`\n",
    "    - `id='scheduled-board'`\n",
    "    \n",
    "The function should take two arguments: the html object from `get_airport_html()` and a string that specifies the `id` you are interested in (by default, the arrivals board).\n",
    "    \n",
    "**Make sure to remove the `pass` statement when you are finished.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d13b576-7447-472a-aa67-389412a173a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_table_soup(html, board = \"arrivals-board\"):\n",
    "    \"\"\" creates a beautiful soup object based on the board of interest\n",
    "    \n",
    "    Args:\n",
    "        html (str): html response from flightaware.com\n",
    "        board (str): board of interest (arrivals, departures, enroute, or scheduled)\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find_all(id = board)\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559b9aa7-bc87-43d0-a7fa-17bbb4f1b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you are done the following code should be run (feel free to change the board if you wish)\n",
    "board_choice = 'arrivals-board'\n",
    "my_board_soup = get_airport_table_soup(url_text, board_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981fb10-b741-4251-9806-32ba3e15248f",
   "metadata": {},
   "source": [
    "## Part 2.3: Cleaning The Board (20 points)\n",
    "\n",
    "Below is the function `clean_board_df()`, which takes the soup object from the previous function and creates a data frame with the following columns:\n",
    "\n",
    "    - `flight number`: the flight number\n",
    "    - `aircraft type`: the type of aircraft\n",
    "    - `airport name`: the name of the originating/destination airport (depending on type of board)\n",
    "    - `airport code`: the letter code of the originating/destination airport\n",
    "    - `departure time`: the time of the flight's departure\n",
    "    - `arrival time`: the time of the flight's arrival\n",
    "\n",
    "I have written the function and (given your function from Part 2.2 works) it should work. **DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTION.**\n",
    "\n",
    "**In a markdown cell** create a bullet point list where you explain each what each chunk of code does. Your bullet point list should have **FOUR** bullet points/explanations corresponding to the four chunks below the `# EXPLAIN THIS (number)` comments. You do not have to be super detailed, but you must accurately summarize the intention of each code chunk. **Talking to your neighbors/group about this is highly recommended.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a65092-fc8a-41bb-9de3-ac4deb703097",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m\n\u001b[0;32m     66\u001b[0m     clean_board_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(clean_board_dict)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clean_board_df\n\u001b[1;32m---> 70\u001b[0m clean_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_board_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_board_soup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m clean_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mclean_board_df\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" takes the soup of a board and cleans it, creating a data frame\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m        arrival time\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# EXPLAIN THIS (1)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[0;32m     19\u001b[0m flight_number \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m aircraft_type \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bs4\\element.py:2428\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2430\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "def clean_board_df(soup):    \n",
    "    \"\"\" takes the soup of a board and cleans it, creating a data frame\n",
    "\n",
    "    Args:\n",
    "        soup (soup): the soup from get_airport_table_soup\n",
    "\n",
    "    Returns:\n",
    "        clean_board_df (data frame): a data frame with six columns corresponding to\n",
    "            flight number\n",
    "            aircraft type\n",
    "            airport name\n",
    "            airport code\n",
    "            departure time\n",
    "            arrival time\n",
    "    \"\"\"\n",
    "    \n",
    "    # EXPLAIN THIS (1)\n",
    "    names = soup.find_all('span', attrs = {'title':True})\n",
    "    flight_number = []\n",
    "    aircraft_type = []\n",
    "    airport_name = []\n",
    "    for idx in range(0, len(names), 3):\n",
    "        flight_number.append(names[idx].text)\n",
    "        aircraft_type.append(names[idx+1].text)\n",
    "        airport_name.append(names[idx+2].text)\n",
    "\n",
    "    # EXPLAIN THIS (2)\n",
    "    codes = soup.find_all(attrs = {'dir': 'ltr'})\n",
    "    airport_code = []\n",
    "    for idx in range(0, len(codes), 2):\n",
    "        airport_code.append(codes[idx+1].text.replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "    # EXPLAIN THIS (3)\n",
    "    times = soup.find_all(class_='tz')\n",
    "    departure_time = []\n",
    "    arrival_time = []\n",
    "    for idx in range(0, len(times), 2):\n",
    "        dep_split_string = times[idx].previous_sibling.split('\\xa0')\n",
    "        arr_split_string = times[idx+1].previous_sibling.split('\\xa0')\n",
    "        \n",
    "        if dep_split_string[0].endswith('a') == True:\n",
    "            dep_datetime_str = dep_split_string[0][:-1] + ' AM'\n",
    "            dep_datetime_time = datetime.strptime(dep_datetime_str, '%I:%M %p').time()\n",
    "            departure_time.append(dep_datetime_time)\n",
    "        else:\n",
    "            dep_datetime_str = dep_split_string[0][:-1] + ' PM'\n",
    "            dep_datetime_time = datetime.strptime(dep_datetime_str, '%I:%M %p').time()\n",
    "            departure_time.append(dep_datetime_time)\n",
    "        \n",
    "        if arr_split_string[0].endswith('a') == True:\n",
    "            arr_datetime_str = arr_split_string[0][:-1] + ' AM'\n",
    "            arr_datetime_time = datetime.strptime(arr_datetime_str, '%I:%M %p').time()\n",
    "            arrival_time.append(arr_datetime_time)\n",
    "        else:\n",
    "            arr_datetime_str = arr_split_string[0][:-1] + ' PM'\n",
    "            arr_datetime_time = datetime.strptime(arr_datetime_str, '%I:%M %p').time()\n",
    "            arrival_time.append(arr_datetime_time)\n",
    "\n",
    "    # EXPLAIN THIS (4)\n",
    "    clean_board_dict = {'flight number': flight_number,\n",
    "                        'aircraft type': aircraft_type,\n",
    "                        'airport name': airport_name,\n",
    "                        'airport code': airport_code,\n",
    "                        'departure time': departure_time,\n",
    "                        'arrival time': arrival_time}\n",
    "    clean_board_df = pd.DataFrame.from_dict(clean_board_dict)\n",
    "    \n",
    "    return clean_board_df\n",
    "    \n",
    "clean_df = clean_board_df(my_board_soup)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4d6c7-c376-4840-b673-54d0d1bd28f8",
   "metadata": {},
   "source": [
    "- Explain Code Chunk 1: this section finds all names in the soup, creates lists for the three items of interest (flight number, aircraft type, and airport name), then loops through the list of all names and sorts the items into the three desired elements. the range function skips by three as the items we're looking for are next to each other, shown by \"names[idx + 1]\" and the like.\n",
    "- Explain Code Chunk 2: this section locates all airport codes in the soup, creates a list, then loops through the list of codes to retrieve all of them, simultaneously cleaning each string by removing parentheses.\n",
    "- Explain Code Chunk 3: this section finds all times in the soup and creates lists. for each pair of times in the set, it separates them into arrival/departure time, uses an if/else block to determine whether the times are AM or PM, adds this to the string, and then converts each date string into datetime objects that can be added to the column list.\n",
    "- Explain Code Chunk 4: this section compiles all the data that was cleaned above into a dictionary with all the desired elements, then turns that dictionary into a pandas dataframe and returns it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576fd51-5d33-4d39-8f28-5e55b1611be5",
   "metadata": {},
   "source": [
    "## Part 2.4: Grabbing More Data (20 points)\n",
    "\n",
    "Below (already written for you) is the function `get_aircraft_info()` which cycles through the different aircraft types in the data frame from the previous part and adds a column with a count of the number of aircrafts currently operating of that type. **DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTION.**\n",
    "\n",
    "**In a markdown cell** explain in why we were able to use `pd.read_html()` instead of `requests.get()` and comment on the values in the new column; is there something off about them?\n",
    "\n",
    "**Hint:** you may want to take a look at an example url in your browser.\n",
    "\n",
    "**Note:** I occasionally got an HTTPS error when running this; just wait a minute and try again, it should eventually work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a287ea9-7e7a-402d-8457-af23a7e0b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aircraft_info(clean_df):\n",
    "    \"\"\" takes a data frame of an aircraft board and adds a column with count of aircraft types\n",
    "\n",
    "    Args:\n",
    "        clean_df (data frame): the output of clean_board_df\n",
    "\n",
    "    Returns:\n",
    "        clean_df (data frame): the same data frame, but with an extra column\n",
    "    \"\"\"\n",
    " \n",
    "    # get a list of aircraft types from the initial data frame\n",
    "    aircraft_type = list(clean_df['aircraft type'])\n",
    "\n",
    "    #initialize an empty list to count the number of each type\n",
    "    num_type = []\n",
    "\n",
    "    # loop through the different types\n",
    "    for idx in range(len(aircraft_type)):\n",
    "\n",
    "        # get the url for each type\n",
    "        craft_url = f'https://flightaware.com/live/aircrafttype/{aircraft_type[idx]}'\n",
    "\n",
    "        # grab the table from the url\n",
    "        craft_tables = pd.read_html(craft_url)\n",
    "\n",
    "        # add the info from the table to the list\n",
    "        num_type.append(craft_tables[2].shape[0])\n",
    "\n",
    "    # turn the list into a series and add it to the data frame\n",
    "    clean_df['num type'] = pd.Series(num_type)\n",
    "\n",
    "    # return the updated data frame\n",
    "    return clean_df\n",
    "\n",
    "final_df = get_aircraft_info(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24455bd-fa20-46c0-8d54-f4b02349f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14b40c-218d-46fa-a2e8-b86527996cba",
   "metadata": {},
   "source": [
    "We can use pd.read_html in this case because the data on this page is formatted as a simple table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
